{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Project 4. Image-Based Lighting - Starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L89RUPncC_lG",
        "colab_type": "text"
      },
      "source": [
        "# CS445: Computational Photography\n",
        "## Programming Project 4: Image-Based Lighting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_cZ-GXwC_lI",
        "colab_type": "text"
      },
      "source": [
        "## Recovering HDR Radiance Maps \n",
        "\n",
        "Load libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR_Edf-XC_lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# jupyter extension that allows reloading functions from imports without clearing kernel :D\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdP7nYtL_3An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoTMQcAJC_lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# System imports\n",
        "from os import path\n",
        "import math\n",
        "\n",
        "# Third-Party Imports\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# modify to where you store your project data including utils\n",
        "datadir = \"/content/drive/My Drive/cs445_projects/proj4/\" \n",
        "\n",
        "utilfn = datadir + \"utils\"\n",
        "!cp -r \"$utilfn\" .\n",
        "samplesfn = datadir + \"samples\"\n",
        "!cp -r \"$samplesfn\" .\n",
        "\n",
        "# can change this to your output directory of choice\n",
        "!mkdir \"images\"\n",
        "!mkdir \"images/outputs\"\n",
        "\n",
        "# import starter code\n",
        "import utils\n",
        "from utils.io import read_image, write_image, read_hdr_image, write_hdr_image\n",
        "from utils.display import display_images_linear_rescale, rescale_images_linear\n",
        "from utils.hdr_helpers import gsolve\n",
        "from utils.hdr_helpers import get_equirectangular_image\n",
        "from utils.bilateral_filter import bilateral_filter\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Ahe8SGmdqo",
        "colab_type": "text"
      },
      "source": [
        "### Reading LDR images\n",
        "\n",
        "You can use the provided samples or your own images.  You get more points for using your own images, but it might help to get things working first with the provided samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c5-ajffC_lS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Replace this with your path and files\n",
        "\n",
        "imdir = 'samples'\n",
        "imfns = ['0024.jpg', '0060.jpg', '0120.jpg', '0205.jpg', '0553.jpg']\n",
        "exposure_times = [1/24.0, 1/60.0, 1/120.0, 1/205.0, 1/553.0]\n",
        "\n",
        "ldr_images = []\n",
        "for f in np.arange(len(imfns)):\n",
        "  im = read_image(imdir + '/' + imfns[f])\n",
        "  if f==0:\n",
        "    imsize = int((im.shape[0] + im.shape[1])/2) # set width/height of ball images\n",
        "    ldr_images = np.zeros((len(imfns), imsize, imsize, 3))\n",
        "  ldr_images[f] = cv2.resize(im, (imsize, imsize))\n",
        "\n",
        "background_image_file = imdir + '/' + 'empty.jpg'\n",
        "background_image = read_image(background_image_file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV8_HCqzC_lZ",
        "colab_type": "text"
      },
      "source": [
        "### Naive LDR merging \n",
        "\n",
        "Compute the HDR image as average of irradiance estimates from LDR images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwD461iRC_la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hdr_naive(ldr_images: np.ndarray, exposures: list) -> (np.ndarray, np.ndarray):\n",
        "    '''\n",
        "    Makes HDR image using multiple LDR images, and its corresponding exposure values.\n",
        "    \n",
        "    The steps to implement:\n",
        "    1) Divide each image by its exposure time.\n",
        "        - This will rescale images as if it has been exposed for 1 second.\n",
        "    \n",
        "    2) Return average of above images\n",
        "    \n",
        "    \n",
        "    For further explanation, please refer to problem page for how to do it.\n",
        "      \n",
        "    Args:\n",
        "        ldr_images(np.ndarray): N x H x W x 3  shaped numpy array representing\n",
        "            N ldr images with width W, height H, and channel size of 3 (RGB)\n",
        "        exposures(list): list of length N, representing exposures of each images.\n",
        "            Each exposure should correspond to LDR images' exposure value.\n",
        "    Return:\n",
        "        (np.ndarray): H x W x 3 shaped numpy array representing HDR image merged using\n",
        "            naive ldr merging implementation.\n",
        "        (np.ndarray): N x H x W x 3  shaped numpy array represending log irradiances\n",
        "            for each exposures\n",
        "            \n",
        "    '''\n",
        "    N, H, W, C = ldr_images.shape\n",
        "    # sanity check\n",
        "    assert N == len(exposures)\n",
        "  \n",
        "    # TO DO\n",
        "  \n",
        "    return hdr_image, log_irradiances\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0c53q30tnBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_hdr_image(im_hdr):\n",
        "    '''\n",
        "    Maps the HDR intensities into a 0 to 1 range and then displays. \n",
        "    Three suggestions to try: \n",
        "      (1) Take log and then linearly map to 0 to 1 range (see display.py for example) \n",
        "      (2) img_out = im_hdr / (1 + im_hdr)\n",
        "      (3) HDR display code in a python package \n",
        "    '''\n",
        "\n",
        "    # TO DO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30DEgK-mC_le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# get HDR image, log irradiance\n",
        "naive_hdr_image, naive_log_irradiances = make_hdr_naive(ldr_images, exposure_times)\n",
        "\n",
        "# write HDR image to directory\n",
        "write_hdr_image(naive_hdr_image, 'images/outputs/naive_hdr.hdr')\n",
        "\n",
        "# display HDR image\n",
        "print('HDR Image')\n",
        "display_hdr_image(naive_hdr_image)\n",
        "\n",
        "# display original images (code provided in utils.display)\n",
        "display_images_linear_rescale(ldr_images)\n",
        "\n",
        "# display log irradiance image (code provided in utils.display)\n",
        "display_images_linear_rescale(naive_log_irradiances)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIpEdB3tC_lh",
        "colab_type": "text"
      },
      "source": [
        "### Weighted LDR merging \n",
        "\n",
        "Compute HDR image as a weighted average of irradiance estimates from LDR images, where weight is based on pixel intensity so that very low/high intensities get less weight\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8oJmPBBC_li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hdr_weighted(ldr_images: np.ndarray, exposure_times: list) -> (np.ndarray, np.ndarray):\n",
        "    '''\n",
        "    Makes HDR image using multiple LDR images, and its corresponding exposure values.\n",
        "    \n",
        "    The steps to implement:\n",
        "    1) compute weights for images with based on intensities for each exposures\n",
        "        - This can be a binary mask to exclude low / high intensity values\n",
        "\n",
        "    2) Divide each images by its exposure time.\n",
        "        - This will rescale images as if it has been exposed for 1 second.\n",
        "    \n",
        "    3) Return weighted average of above images\n",
        "    \n",
        "    \n",
        "    Args:\n",
        "        ldr_images(np.ndarray): N x H x W x 3 shaped numpy array representing\n",
        "            N ldr images with width W, height H, and channel size of 3 (RGB)\n",
        "        exposure_times(list): list of length N, representing exposures of each images.\n",
        "            Each exposure should correspond to LDR images' exposure value.\n",
        "    Return:\n",
        "        (np.ndarray): H x W x 3 shaped numpy array representing HDR image merged without\n",
        "            under - over exposed regions\n",
        "\n",
        "    '''\n",
        "    N, H, W, C = ldr_images.shape\n",
        "    # sanity check\n",
        "    assert N == len(exposure_times)\n",
        "    \n",
        "    # TO DO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLmGn7GqC_ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get HDR image, log irradiance\n",
        "weighted_hdr_image = make_hdr_weighted(ldr_images, exposure_times)\n",
        "\n",
        "# write HDR image to directory\n",
        "write_hdr_image(weighted_hdr_image, 'images/outputs/weighted_hdr.hdr')\n",
        "\n",
        "# display HDR image\n",
        "display_hdr_image(weighted_hdr_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34W3JJk1qPgR",
        "colab_type": "text"
      },
      "source": [
        "Display of difference between naive and weighted for your own inspection\n",
        "\n",
        "Where does the weighting make a big difference increasing or decreasing the irradiance estimate?  Think about why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AyihfPZqTz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display difference between naive and weighted \n",
        "\n",
        "log_diff_im = np.log(weighted_hdr_image)-np.log(naive_hdr_image)\n",
        "print('Min ratio = ', np.exp(log_diff_im).min(), '  Max ratio = ', np.exp(log_diff_im).max())\n",
        "plt.figure()\n",
        "plt.imshow(rescale_images_linear(log_diff_im))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6qnwuifC_lp",
        "colab_type": "text"
      },
      "source": [
        "### LDR merging with camera response function estimation \n",
        "\n",
        "Compute HDR after calibrating the photometric reponses to obtain more accurate irradiance estimates from each image\n",
        "\n",
        "Some suggestions on using <tt>gsolve</tt>:\n",
        "<ul>\n",
        "\t<li>When providing input to gsolve, don't use all available pixels, otherwise you will likely run out of memory / have very slow run times. To overcome, just randomly sample a set of pixels (1000 or so can suffice), but make sure all pixel locations are the same for each exposure.</li>\n",
        "\t<li>The weighting function w should be implemented using Eq. 4 from the paper (this is the same function that can be used for the previous LDR merging method).</li>\n",
        "\t<li>Try different lambda values for recovering <i>g</i>. Try lambda=1 initially, then solve for <i>g</i> and plot it. It should be smooth and continuously increasing. If lambda is too small, g will be bumpy.</li>\n",
        "\t<li>Refer to Eq. 6 in the paper for using g and combining all of your exposures into a final image. Note that this produces log irradiance values, so make sure to exponentiate the result and save irradiance in linear scale.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpXG0GTeC_lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hdr_estimation(ldr_images: np.ndarray, exposure_times: list, lm)-> (np.ndarray, np.ndarray):\n",
        "    '''\n",
        "    Makes HDR image using multiple LDR images, and its corresponding exposure values.\n",
        "    Please refer to problem notebook for how to do it.\n",
        "    \n",
        "    **IMPORTANT**\n",
        "    The gsolve operations should be ran with:\n",
        "        Z: int64 array of shape N x P, where N = number of images, P = number of pixels\n",
        "        B: float32 array of shape N, log shutter times\n",
        "        l: lambda; float to control amount of smoothing\n",
        "        w: function that maps from float intensity to weight  \n",
        "    The steps to implement:\n",
        "    1) Create random points to sample (from mirror ball region)\n",
        "    2) For each exposures, compute g values using samples\n",
        "    3) Recover HDR image using g values\n",
        "    \n",
        "\n",
        "    Args:\n",
        "        ldr_images(np.ndarray): N x H x W x 3 shaped numpy array representing\n",
        "            N ldr images with width W, height H, and channel size of 3 (RGB)\n",
        "        exposures(list): list of length N, representing exposures of each images.\n",
        "            Each exposure should correspond to LDR images' exposure value.\n",
        "        lm (scalar): the smoothing parameter\n",
        "    Return:\n",
        "        (np.ndarray): H x W x 3 shaped numpy array representing HDR image merged using\n",
        "            gsolve\n",
        "        (np.ndarray): N x H x W x 3 shaped numpy array represending log irradiances\n",
        "            for each exposures\n",
        "        (np.ndarray): 3 x 256 shaped numpy array represending g values of each pixel intensities\n",
        "            at each channels (used for plotting)\n",
        "    '''\n",
        "    N, H, W, C = ldr_images.shape\n",
        "    # sanity check\n",
        "    assert N == len(exposure_times)\n",
        "    \n",
        "    # TO DO: implement HDR estimation using gsolve\n",
        "    # gsolve(Z, B, l, w) -> g, lE\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOQsK915C_lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = 5\n",
        "# get HDR image, log irradiance\n",
        "calib_hdr_image, calib_log_irradiances, g = make_hdr_estimation(ldr_images, exposure_times, lm)\n",
        "\n",
        "# write HDR image to directory\n",
        "write_hdr_image(calib_hdr_image, 'images/outputs/calib_hdr.hdr')\n",
        "\n",
        "# display HDR image\n",
        "display_hdr_image(calib_hdr_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m43yPxHoUYp",
        "colab_type": "text"
      },
      "source": [
        "The following code displays your results. You can copy the resulting images and plots directly into your report where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks-FGGf8oRXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display difference between calibrated and weighted\n",
        "log_diff_im = np.log(calib_hdr_image/calib_hdr_image.mean())-np.log(weighted_hdr_image/weighted_hdr_image.mean())\n",
        "print('Min ratio = ', np.exp(log_diff_im).min(), '  Max ratio = ', np.exp(log_diff_im).max())\n",
        "plt.figure()\n",
        "plt.imshow(rescale_images_linear(log_diff_im))\n",
        "\n",
        "# display original images (code provided in utils.display)\n",
        "display_images_linear_rescale(ldr_images)\n",
        "\n",
        "# display log irradiance image (code provided in utils.display)\n",
        "display_images_linear_rescale(calib_log_irradiances)\n",
        "\n",
        "# plot g vs intensity, and then plot intensity vs g\n",
        "N, NG = g.shape\n",
        "labels = ['R', 'G', 'B']\n",
        "plt.figure()\n",
        "for n in range(N):\n",
        "    plt.plot(g[n], range(NG), label=labels[n])\n",
        "plt.gca().legend(('R', 'G', 'B'))\n",
        "\n",
        "plt.figure()\n",
        "for n in range(N):\n",
        "    plt.plot(range(NG), g[n], label=labels[n])\n",
        "plt.gca().legend(('R', 'G', 'B'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiblo-1u4Nom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_log_error(ldr_images, hdr_image, log_irradiances):\n",
        "  # computes weighted RMS error of log irradiances for each image compared to final log irradiance\n",
        "  N, H, W, C = ldr_images.shape\n",
        "  w = 1-abs(ldr_images - 0.5)*2\n",
        "  err = 0\n",
        "  for n in np.arange(N):\n",
        "    err += np.sqrt(np.multiply(w[n], (log_irradiances[n]-np.log(hdr_image))**2).sum()/w[n].sum())/N \n",
        "  return err\n",
        "\n",
        "\n",
        "# compare solutions\n",
        "err = weighted_log_error(ldr_images, naive_hdr_image, naive_log_irradiances)\n",
        "print('naive:  \\tlog range = ', round(np.log(naive_hdr_image).max() - np.log(naive_hdr_image).min(),3), '\\tavg RMS error = ', round(err,3))\n",
        "err = weighted_log_error(ldr_images, weighted_hdr_image, naive_log_irradiances)\n",
        "print('weighted:\\tlog range = ', round(np.log(weighted_hdr_image).max() - np.log(weighted_hdr_image).min(),3), '\\tavg RMS error = ', round(err,3))\n",
        "err = weighted_log_error(ldr_images, calib_hdr_image, calib_log_irradiances)\n",
        "print('calibrated:\\tlog range = ', round(np.log(calib_hdr_image).max() - np.log(calib_hdr_image).min(),3), '\\tavg RMS error = ', round(err,3))\n",
        "\n",
        "# display log hdr images (code provided in utils.display)\n",
        "display_images_linear_rescale(np.log(np.stack((naive_hdr_image/naive_hdr_image.mean(), weighted_hdr_image/weighted_hdr_image.mean(), calib_hdr_image/calib_hdr_image.mean()), axis=0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxGGvTfBC_l0",
        "colab_type": "text"
      },
      "source": [
        "## Panoramic transformations \n",
        "\n",
        "Compute the equirectangular image from the mirrorball image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOjdj36bC_l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def panoramic_transform(hdr_image):\n",
        "    '''\n",
        "    Given HDR mirror ball image, \n",
        "    \n",
        "    Expects mirror ball image to have center of the ball at center of the image, and\n",
        "    width and height of the image to be equal.\n",
        "    \n",
        "    Steps to implement:\n",
        "    1) Compute N image of normal vectors of mirror ball\n",
        "    2) Compute R image of reflection vectors of mirror ball\n",
        "    3) Map reflection vectors into spherical coordinates\n",
        "    4) Interpolate spherical coordinate values into equirectangular grid.\n",
        "    \n",
        "    Steps 3 and 4 are implemented for you with get_equirectangular_image\n",
        "\n",
        "    '''\n",
        "    H, W, C = hdr_image.shape\n",
        "    assert H == W\n",
        "    assert C == 3\n",
        "\n",
        "    # TO DO: compute N and R\n",
        "        \n",
        "    # R = V - 2 * dot(V,N) * N\n",
        "\n",
        "\n",
        "    \n",
        "    plt.imshow((N+1)/2)\n",
        "    plt.show()\n",
        "    plt.imshow((R+1)/2)\n",
        "    plt.show()\n",
        "\n",
        "    equirectangular_image = get_equirectangular_image(R, hdr_image)\n",
        "    return equirectangular_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcSKLTR9C_l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hdr_mirrorball_image = read_hdr_image('images/outputs/calib_hdr.hdr')\n",
        "eq_image = panoramic_transform(hdr_mirrorball_image)\n",
        "\n",
        "write_hdr_image(eq_image, 'images/outputs/equirectangular.hdr')\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "display_hdr_image(eq_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6r7i_XLC_l8",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlBggErHC_l8",
        "colab_type": "text"
      },
      "source": [
        "## Rendering synthetic objects into photographs \n",
        "\n",
        "Use Blender to render the scene with and with objects and obtain the mask image.  The code below should then load the images and create the final composite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfj1FvtHC_l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the images that you produced using Blender.  Modify names as needed.\n",
        "O = read_image('images/proj4_objects.png')\n",
        "E = read_image('images/proj4_empty.png')\n",
        "M = read_image('images/proj4_mask.png')\n",
        "M = M > 0.5\n",
        "I = background_image\n",
        "I = cv2.resize(I, (M.shape[1], M.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ7nfFvAC_mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: compute final composite\n",
        "result = []\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(result)\n",
        "plt.show()\n",
        "\n",
        "write_image(result, 'images/outputs/final_composite.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjv48QfAC_mF",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omtrcz0nC_mF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Bells & Whistles (Extra Points)\n",
        "\n",
        "### Additional Image-Based Lighting Result \n",
        "\n",
        "\n",
        "### Other panoramic transformations \n",
        "\n",
        "\n",
        "### Photographer/tripod removal \n",
        "\n",
        "\n",
        "### Local tonemapping operator \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjVhB_fOC_mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}