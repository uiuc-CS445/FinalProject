{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L89RUPncC_lG"
   },
   "source": [
    "# CS445: Computational Photography\n",
    "## Programming Project 4: Image-Based Lighting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_cZ-GXwC_lI"
   },
   "source": [
    "## Recovering HDR Radiance Maps \n",
    "\n",
    "Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR_Edf-XC_lJ"
   },
   "outputs": [],
   "source": [
    "# jupyter extension that allows reloading functions from imports without clearing kernel :D\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdP7nYtL_3An"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoTMQcAJC_lN"
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "from os import path\n",
    "import math\n",
    "\n",
    "# Third-Party Imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "%matplotlib inline\n",
    "from random import random\n",
    "import time\n",
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Video\n",
    "import shutil\n",
    "\n",
    "# modify to where you store your project data including utils\n",
    "datadir = \"C:/Users/chaob/Desktop/445/finalproject/fp/FinalProject\" \n",
    "\n",
    "utilfn = datadir + \"utils\"\n",
    "# !cp -r \"$utilfn\" .\n",
    "samplesfn = datadir + \"samples\"\n",
    "# !cp -r \"$samplesfn\" .\n",
    "\n",
    "# can change this to your output directory of choice\n",
    "# !mkdir \"images\"\n",
    "# !mkdir \"images/outputs\"\n",
    "\n",
    "# import starter code\n",
    "import utils\n",
    "from utils.io import read_image, write_image, read_hdr_image, write_hdr_image\n",
    "from utils.display import display_images_linear_rescale, rescale_images_linear\n",
    "from utils.hdr_helpers import gsolve\n",
    "from utils.hdr_helpers import get_equirectangular_image\n",
    "from utils.bilateral_filter import bilateral_filter\n",
    "from utils.bilateral_filter import bilateral_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0Ahe8SGmdqo"
   },
   "source": [
    "### Reading Videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0c5-ajffC_lS"
   },
   "outputs": [],
   "source": [
    "def import_video(video_path):\n",
    "\n",
    "    # Create a directory to store the extracted frames\n",
    "    output_folder = 'frames'+ '/' + vname\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(output_folder):\n",
    "        # If it exists, remove the directory and its contents\n",
    "        shutil.rmtree(output_folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the video properties\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Initialize variables\n",
    "    frame_count = 0\n",
    "    frames = []\n",
    "\n",
    "    # Read frames from the video\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save the frame as an image in the output folder\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Frames extracted: {frame_count}\")\n",
    "    print(f\"Frames saved in the folder: {output_folder}\")\n",
    "\n",
    "    return frames, width, height, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 144\n",
      "Frames extracted: 144\n",
      "Frames saved in the folder: frames/cat1\n"
     ]
    }
   ],
   "source": [
    "imdir = 'samples'\n",
    "vname = 'cat1'\n",
    "\n",
    "# Specify the path to the video file\n",
    "video_path = imdir + '/' + vname +'.mp4'\n",
    "\n",
    "# Import the video and get the frames and video properties\n",
    "frames, width, height, fps = import_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples/cat1.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"samples/cat1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the video in the notebook\n",
    "video = Video(video_path)\n",
    "print(video_path)\n",
    "display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First frame is background, or can be frames[0]\n",
    "background_image_file = 'frames'+ '/' + vname + '/' +'frame_0000.jpg'\n",
    "background_image = read_image(background_image_file)\n",
    "\n",
    "# background_image_file = imdir + '/' + 'empty.jpg'\n",
    "# background_image = read_image(background_image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DV8_HCqzC_lZ"
   },
   "source": [
    "### Background removal\n",
    "\n",
    "Compute the HDR image as average of irradiance estimates from LDR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_subtraction_o(frames, width, height, fps, vname):\n",
    "    # Create directories to store the output frames and video\n",
    "    output_folder_bs = \"background_removed_frames_o\" + '/' + vname\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(output_folder_bs):\n",
    "        # If it exists, remove the directory and its contents\n",
    "        shutil.rmtree(output_folder_bs)\n",
    "    os.makedirs(output_folder_bs, exist_ok=True)\n",
    "    \n",
    "    # Read the first frame as the background image\n",
    "    background = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply blurring to the background frame\n",
    "    blurred_background = cv2.GaussianBlur(background, (15, 15), 0)\n",
    "    \n",
    "    # Initialize variables\n",
    "    processed_frames = []\n",
    "    \n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((200, 200), np.uint8)\n",
    "    \n",
    "    # Process frames for background subtraction\n",
    "    for i, frame in enumerate(frames):\n",
    "        # Convert the frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply blurring to the grayscale frame\n",
    "        blurred_frame = cv2.GaussianBlur(gray_frame, (15, 15), 0)\n",
    "        \n",
    "        # Perform background subtraction\n",
    "        diff = cv2.absdiff(blurred_background, blurred_frame)\n",
    "        \n",
    "        # Apply thresholding\n",
    "        threshold = 60\n",
    "        _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Apply erosion\n",
    "        eroded = cv2.erode(thresh, kernel, iterations=10)\n",
    "        \n",
    "        # # Apply dilation\n",
    "        dilated = cv2.dilate(eroded, kernel, iterations=3)\n",
    "        \n",
    "        # Save the thresholded frame as an image in the output folder\n",
    "        frame_path_bs = os.path.join(output_folder_bs, f\"frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path_bs, thresh)\n",
    "        \n",
    "        # Append the processed frame to the list\n",
    "        processed_frames.append(thresh)\n",
    "    \n",
    "    print(f\"Background subtraction completed.\")\n",
    "    print(f\"Output frames saved in the folder: {output_folder_bs}\")\n",
    "    \n",
    "    return processed_frames, output_folder_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background subtraction completed.\n",
      "Output frames saved in the folder: background_removed_frames_o/cat1\n"
     ]
    }
   ],
   "source": [
    "# Perform background subtraction on the frames and get the processed frames\n",
    "processed_frames_o, output_folder_bs_o = background_subtraction_o(frames, width, height, fps, vname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -framerate 30 -i \"{output_folder_bs_o}/frame_%04d.jpg\" -c:v libx264 -pix_fmt yuv420p \"{output_folder_bs_o}/bs_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#会占用导致无法更改，最后展示用\n",
    "# # Display the video in the notebook\n",
    "# v=\"background_removed_frames/cat1/bs_video.mp4\"\n",
    "# video = Video(v)\n",
    "# display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_subtraction_improve(frames, width, height, fps, vname):\n",
    "    # Create directories to store the output frames and video\n",
    "    output_folder_bs = \"background_removed_frames_improve\" + '/' + vname\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(output_folder_bs):\n",
    "        # If it exists, remove the directory and its contents\n",
    "        shutil.rmtree(output_folder_bs)\n",
    "    os.makedirs(output_folder_bs, exist_ok=True)\n",
    "        \n",
    "    # Initialize variables\n",
    "    processed_frames = []\n",
    "    \n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((80, 80), np.uint8)\n",
    "    \n",
    "    # Create a GMM-based background subtractor\n",
    "    background_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows=True)\n",
    "    \n",
    "    # Define the number of initial frames to skip or use for training\n",
    "    num_initial_frames = 5\n",
    "\n",
    "    # Train the background subtractor on initial frames\n",
    "    for i in range(num_initial_frames):\n",
    "        frame = frames[i]\n",
    "        blurred_frame = cv2.GaussianBlur(frame, (35, 35), 0)\n",
    "        _ = background_subtractor.apply(blurred_frame)\n",
    "\n",
    "    # Process frames for background subtraction\n",
    "    for i, frame in enumerate(frames):\n",
    "        \n",
    "        blurred_frame = cv2.GaussianBlur(frame, (35, 35), 0)\n",
    "        # Apply background subtraction\n",
    "        mask = background_subtractor.apply(blurred_frame)\n",
    "\n",
    "        # Apply thresholding to the mask\n",
    "        _, thresh = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "       \n",
    "        # Apply erosion\n",
    "        eroded = cv2.erode(thresh, kernel, iterations=2)\n",
    "        \n",
    "        # # Apply dilation\n",
    "        dilated = cv2.dilate(eroded, kernel, iterations=10)\n",
    "        \n",
    "        # Save the thresholded frame as an image in the output folder\n",
    "        frame_path_bs = os.path.join(output_folder_bs, f\"frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path_bs, thresh)\n",
    "        \n",
    "        # Append the processed frame to the list\n",
    "        processed_frames.append(thresh)\n",
    "    \n",
    "    print(f\"Background subtraction completed.\")\n",
    "    print(f\"Output frames saved in the folder: {output_folder_bs}\")\n",
    "    \n",
    "    return processed_frames, output_folder_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background subtraction completed.\n",
      "Output frames saved in the folder: background_removed_frames_improve/cat1\n"
     ]
    }
   ],
   "source": [
    "# Perform background subtraction on the frames and get the processed frames\n",
    "processed_frames_improve, output_folder_bs_improve = background_subtraction_improve(frames, width, height, fps, vname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -framerate 30 -i \"{output_folder_bs_improve}/frame_%04d.jpg\" -c:v libx264 -pix_fmt yuv420p \"{output_folder_bs_improve}/bs_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_white_regions(image_path):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Check if any contours were found\n",
    "    if len(contours) > 0:\n",
    "        # Find the area of the largest contour\n",
    "        largest_area = max(cv2.contourArea(contour) for contour in contours)\n",
    "        \n",
    "        # Set the area threshold to be the area of the largest contour minus 200\n",
    "        area_threshold = largest_area - 0.05*largest_area\n",
    "        \n",
    "        # Create a mask to store the filtered white regions\n",
    "        mask = np.zeros_like(image)\n",
    "        \n",
    "        # Iterate over each contour\n",
    "        for contour in contours:\n",
    "            # Calculate the area of the contour\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # If the area is greater than or equal to the threshold, draw the contour on the mask\n",
    "            if area > 2000 and area >= area_threshold:\n",
    "                cv2.drawContours(mask, [contour], 0, 255, -1)\n",
    "        \n",
    "        # Apply the mask to the original image\n",
    "        result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    else:\n",
    "        # If no contours were found, return the original image\n",
    "        result = image\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the folder path containing the black and white images\n",
    "folder_path = output_folder_bs_improve\n",
    "\n",
    "# Create a new folder to store the processed images\n",
    "out_folder = \"obj_frames_improve\" + '/' + vname\n",
    "# Check if the directory exists\n",
    "if os.path.exists(out_folder):\n",
    "    # If it exists, remove the directory and its contents\n",
    "    shutil.rmtree(out_folder)\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Iterate over each image file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") :  # Adjust the file extensions as needed\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Process the image to keep the white regions with areas greater than or equal to the threshold\n",
    "        processed_image = filter_white_regions(image_path)\n",
    "        \n",
    "        # Save the processed image to the output folder\n",
    "        output_path = os.path.join(out_folder, filename)\n",
    "        cv2.imwrite(output_path, processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!ffmpeg -framerate 30 -i \"{out_folder}/frame_%04d.jpg\" -c:v libx264 -pix_fmt yuv420p \"{out_folder}/obj_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjVhB_fOC_mG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project 4. Image-Based Lighting - Starter.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
